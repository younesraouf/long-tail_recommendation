import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import time

# --- IMPORTS DES MODULES DU PROJET ---
# On suppose que le dossier 'src' est au m√™me niveau que app.py
from src.data_loader import DataLoader
from src.cf_model import ItemBasedCF
from src.optimizer import MORSOptimizer

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(
    page_title="MORS Recommender System",
    page_icon="üé¨",
    layout="wide"
)

st.title("üé¨ MORS: Multi-Objective Recommendation")
st.markdown("""
**Syst√®me de recommandation optimisant la Longue Tra√Æne.**  
Ce dashboard permet de visualiser le compromis entre la **Pr√©cision** (Items populaires) et la **Nouveaut√©** (Items de niche/Long Tail).
""")

# --- FONCTIONS UTILITAIRES ---

@st.cache_resource
def load_system(dataset_name):
    """
    Charge les donn√©es, entra√Æne le mod√®le CF et pr√©pare les stats.
    Mis en cache pour la performance.
    """
    status_text = st.empty()
    bar = st.progress(0)
    
    # 1. Chargement Donn√©es
    status_text.text(f"Chargement du dataset {dataset_name}...")
    # CORRECTION DU CHEMIN ICI : On force le chemin relatif depuis la racine
    loader = DataLoader(active_dataset=dataset_name, processed_data_dir="data/processed")
    df = loader.load_active_dataset()
    titles = loader.load_item_titles()
    bar.progress(25)
    
    # 2. Split & Stats
    status_text.text("Calcul des statistiques (Moyenne/Variance)...")
    train_df, _ = loader.get_train_test_split(df)
    item_stats = loader.get_item_statistics(train_df)
    bar.progress(50)
    
    # 3. Matrice & CF
    status_text.text("Construction de la matrice User-Item et calcul de similarit√©...")
    train_matrix = loader.get_user_item_matrix(train_df)
    cf = ItemBasedCF(train_matrix)
    cf.compute_similarity()
    bar.progress(100)
    
    status_text.empty()
    bar.empty()
    
    return loader, df, item_stats, cf, titles

def split_pareto_solutions(solutions):
    """
    S√©pare les solutions en deux listes : 
    1. Le Front de Pareto (Non-domin√©es)
    2. Les solutions domin√©es (Le nuage gris)
    """
    pareto = []
    dominated = []
    
    for sol_a in solutions:
        is_dominated = False
        for sol_b in solutions:
            # Si sol_b est meilleure ou √©gale partout, et strictement meilleure sur au moins un point
            if (sol_b['accuracy'] >= sol_a['accuracy'] and 
                sol_b['novelty'] >= sol_a['novelty'] and 
                (sol_b['accuracy'] > sol_a['accuracy'] or sol_b['novelty'] > sol_a['novelty'])):
                is_dominated = True
                break
        
        if is_dominated:
            dominated.append(sol_a)
        else:
            pareto.append(sol_a)
            
    # Tri du front pour tracer une ligne propre
    pareto.sort(key=lambda x: x['accuracy'])
    return pareto, dominated

def plot_pareto_advanced(pareto_sols, dominated_sols):
    """G√©n√®re le graphique avanc√© avec distinction Front/Nuage."""
    
    par_acc = [s['accuracy'] for s in pareto_sols]
    par_nov = [s['novelty'] for s in pareto_sols]
    dom_acc = [s['accuracy'] for s in dominated_sols]
    dom_nov = [s['novelty'] for s in dominated_sols]
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # 1. Nuage gris (Solutions explor√©es mais rejet√©es)
    ax.scatter(dom_acc, dom_nov, c='gray', alpha=0.3, s=30, label='Solutions explor√©es', zorder=1)
    
    # 2. Ligne du Front
    ax.plot(par_acc, par_nov, c='#1f77b4', linewidth=2, alpha=0.8, zorder=2)
    
    # 3. Points du Front (Optimaux)
    ax.scatter(par_acc, par_nov, c='#1f77b4', s=60, edgecolors='white', label='Front de Pareto', zorder=3)
    
    # 4. Extr√™mes (√âtoiles)
    if len(pareto_sols) > 0:
        # Max Pr√©cision (Dernier de la liste tri√©e par accuracy)
        ax.scatter(par_acc[-1], par_nov[-1], c='crimson', s=180, marker='*', label='Max Pr√©cision', zorder=4)
        
        # Max Nouveaut√© (Celui qui a le score novelty le plus haut)
        idx_max_nov = max(range(len(par_nov)), key=par_nov.__getitem__)
        ax.scatter(par_acc[idx_max_nov], par_nov[idx_max_nov], c='limegreen', s=180, marker='*', label='Max Nouveaut√©', zorder=4)

    ax.set_title("Espace de recherche & Front de Pareto", fontsize=14)
    ax.set_xlabel("Pr√©cision (Somme des notes pr√©dites)")
    ax.set_ylabel("Nouveaut√© (Score Long Tail)")
    ax.grid(True, linestyle=':', alpha=0.5)
    ax.legend(loc='upper right')
    
    return fig

def show_list_with_highlight(sol, label, titles_map, highlight_items=None):
    """Affiche une liste de films en ajoutant des √©mojis pour les nouveaut√©s."""
    if highlight_items is None: highlight_items = set()
    
    data = []
    for item_id in sol['items']:
        title = titles_map.get(item_id, f"Item {item_id}")
        if item_id in highlight_items:
            title = f"‚ú® {title}" # Marqueur visuel
        data.append(title)
        
    df_res = pd.DataFrame({"Films Recommand√©s": data})
    st.markdown(f"**{label}**")
    st.caption(f"Pr√©cision: {sol['accuracy']:.2f} | Nouveaut√©: {sol['novelty']:.2f}")
    st.dataframe(df_res, height=300, use_container_width=True)

# --- INTERFACE SIDEBAR ---
st.sidebar.header("‚öôÔ∏è Configuration")

ds_choice = st.sidebar.selectbox("Choisir le Dataset", ["movielens", "jester", "netflix"])
user_id = st.sidebar.number_input("ID Utilisateur Cible", min_value=1, value=1)

st.sidebar.subheader("Param√®tres Algorithme (MORS)")
k_items = st.sidebar.slider("Longueur de la liste (K)", 5, 20, 10)
n_gen = st.sidebar.slider("G√©n√©rations", 10, 300, 100) # Augment√© un peu par d√©faut
pop_size = st.sidebar.slider("Taille Population", 10, 100, 50)

# --- CORPS PRINCIPAL ---

# 1. Chargement initial
try:
    loader, df, item_stats, cf, titles = load_system(ds_choice)
    st.success(f"Syst√®me charg√© : {ds_choice.capitalize()} ({len(df)} notes).")
except Exception as e:
    st.error(f"Erreur de chargement : {e}")
    st.stop()

# 2. Onglets
tab1, tab2 = st.tabs(["üìä Analyse Dataset", "üöÄ Recommandation MORS"])

with tab1:
    st.subheader("Distribution Longue Tra√Æne")
    item_counts = df.groupby('item_id').size().sort_values(ascending=False).values
    
    fig_tail, ax_tail = plt.subplots(figsize=(12, 5))
    ax_tail.plot(item_counts, color='blue')
    ax_tail.fill_between(range(len(item_counts)), item_counts, color='blue', alpha=0.1)
    
    cutoff = int(len(item_counts) * 0.2)
    ax_tail.axvline(x=cutoff, color='red', linestyle='--')
    ax_tail.text(cutoff*1.1, max(item_counts)*0.8, 'Fronti√®re 20/80', color='red')
    
    ax_tail.set_title(f"Distribution des notes - {ds_choice}")
    ax_tail.set_ylabel("Nombre de notes")
    ax_tail.set_xlabel("Items (tri√©s par popularit√©)")
    st.pyplot(fig_tail)
    
    col_a, col_b = st.columns(2)
    col_a.metric("Nombre total d'items", len(item_counts))
    col_b.metric("Items en Long Tail (>80%)", int(len(item_counts)*0.8))

with tab2:
    if st.button("Lancer l'Optimisation", type="primary"):
        
        # A. Phase 1 : Candidats CF
        with st.spinner("Phase 1 : G√©n√©ration des candidats (Item-Based CF)..."):
            if user_id not in cf.train_matrix.index:
                st.error(f"L'utilisateur {user_id} n'existe pas dans le Train Set.")
                candidates = []
            else:
                candidates = cf.get_top_k_candidates(user_id, k=k_items*5)
        
        if len(candidates) > 0:
            # B. Phase 2 : Optimisation MORS
            with st.spinner(f"Phase 2 : √âvolution g√©n√©tique ({n_gen} g√©n√©rations)..."):
                optimizer = MORSOptimizer(
                    candidates, 
                    item_stats, 
                    list_length=k_items, 
                    population_size=pop_size
                )
                solutions = optimizer.run(generations=n_gen)
            
            # C. Traitement des r√©sultats (S√©paration Front vs Nuage)
            pareto_sols, dominated_sols = split_pareto_solutions(solutions)
            
            st.divider()
            col_graph, col_list = st.columns([1.5, 1])
            
            with col_graph:
                st.subheader("Visualisation des Solutions")
                fig_pareto = plot_pareto_advanced(pareto_sols, dominated_sols)
                st.pyplot(fig_pareto)
                
                st.info(f"Solutions g√©n√©r√©es : {len(solutions)} | Optimales (Pareto) : {len(pareto_sols)}")
            
            with col_list:
                st.subheader("Comparaison des Listes")
                
                # S√©lection des meilleures solutions
                # Le front est tri√© par accuracy croissante -> Le dernier est Max Acc
                sol_acc = pareto_sols[-1]
                # Le max novelty peut √™tre n'importe o√π, on le cherche
                sol_nov = max(pareto_sols, key=lambda x: x['novelty'])
                
                # Identification des items "D√©couverte" (pr√©sents dans Nov mais pas dans Acc)
                items_in_acc = set(sol_acc['items'])
                items_in_nov = set(sol_nov['items'])
                discoveries = items_in_nov - items_in_acc

                sub_tab1, sub_tab2 = st.tabs(["üéØ Max Pr√©cision", "üåü Max Nouveaut√©"])
                
                with sub_tab1:
                    show_list_with_highlight(sol_acc, "Focus : Qualit√© Pr√©dite", titles)
                
                with sub_tab2:
                    show_list_with_highlight(sol_nov, "Focus : D√©couverte (Long Tail)", titles, highlight_items=discoveries)
                    if len(discoveries) > 0:
                        st.success(f"L'algo a introduit {len(discoveries)} items originaux (marqu√©s par ‚ú®).")
                    else:
                        st.warning("Les listes sont identiques (Compromis difficile √† trouver pour cet utilisateur).")
                    
        elif user_id in cf.train_matrix.index:
            st.warning("Aucun candidat trouv√© (Cold Start ou pas assez de donn√©es).")